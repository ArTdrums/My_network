# My_network
Данная нейросеть является полносвязной и  написана без фреймворков, сторонних библиотек по созданию и обучению неройнных сетей.
Она является универсальной и принимает значения в виде одномерного массива ( сделано для удобства предоставляния информации для различных задач).
Так же она может быть переделана в свертоную нейронную сеть. ( будет показано ниже)
Начинаем создания класса NeuraNetwork, который принимает колличество сигналов на входном, скртом и выходном слоеи коэффециент обучения(input_nodes, hidden_nodes, output_nodes,
                 lerninggrate).
Создаем случайные матрицы весов между входным и скрытым слое, скрытым и выходным.
создаем коэффеиент обучения и функцию активации.

создаем метод  quary, который принимает список входных значений.
далее идет расчет входящих и иходящих сигналов каждого слоя.
#расчет входящих сигналов для скрытого слоя расчитывается путем умножения матрицы весов ( скрытого и входящего слоя на значения сигнала, поступивзего на нейрон).
#расчет исходящего  сигналов для скрытого вычислиется путем применения к полученному входящему сигналу функции активации ( в качетсве функции активаци выбрана сигмоида).
#для остальных слоев по аналогии.
метод  quary возвращает выходной сигнал каждого нейрона.

создаем метод def train,  который принимает список входных значений и список класификации(inputs_list, target_list) обьектов( маркеры).
значения наши обьектов переводим в дмумерный массив и ранспонирвкем( для удобства матричного умножения).
как и методе quary создаем входные/выходные значения для нейронов каждого слоя.
в качетсво обучения используется метод обратного распространения ошибка путем градиентног спуска от выходного слоя, через скрытый к входному.
Ошибку выходного слоя считаем как разницу межды желаемым и полученным значением.
Обучение проходит от выходного слоя к входному и вычисляется как кожффециент обучения * (ошибка выходного слоя * выходной слой * (1-выхдной слой)), массив скрытого слоя таспонированный)
следующему слоя по аналогии, с учетом поправди на слои.
задается колличество нейронов на каждом слое, задается коэффециент обучения и создается экземпляр класса нейронной сети.

Переходим к подготовке данных (prepair_data_set).
заружаем картинку и изобразение кота/ собаки ( закоментировал кусок кода, когда можно через цикл загрузить бесконечно большое колличество картинок, что сформирует отличный дата сет и обучет нейроесть).
Картинка представлена в формате GRB и содержет данные в трехмерном массиве.
Переводим данные в одномерный массив  т.к мы изначально написали прием данныех в виде одномерного массива (подаем одно значение на один нейрон).
Уменьшаем картинку до размера 28х28 ( для удобства обучения нейросети, т.к нейросеть полносвязная)
изображение 28х28 дает нам 784 нейрона на входящем слое,на которые мы будем подават по одному значению
далее преобразовываем данные так, что бы они выбли он 0 до 1 ( для нормализации обучения нейронки, если данные будут большими ( в нашем случает от 0 до 255), то обучение может застопориться, т.к градиен может стремиться к 
0, это особенности функции активации сигмоида)
После подготовки данных можем подавать их на неросеть, сохранять обученные веса в csv. файл и в дальнейшем использовать для классификации обьектов









